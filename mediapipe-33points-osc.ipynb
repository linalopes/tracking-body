{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "- cv2: To capture and manipulate video frames (e.g., from a webcam) and prepare them for processing.\n",
    "- mediapipe: To analyze video frames and extract landmarks (e.g., hand or face tracking). This is the machine-learning model used in this project.\n",
    "- python-osc: To send processed data (e.g., landmark positions) via the OSC protocol to external software or devices. In this case, it's sending to processing 4.\n",
    "\n",
    "\n",
    "Make sure to have the following installed in the enviroment:\n",
    "- `mediapipe`: For landmark detection.\n",
    "- `python-osc`: To send data via OSC.\n",
    "- `cv2` (OpenCV): To capture and handle video frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "from pythonosc.udp_client import SimpleUDPClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up OSC and MediaPipe\n",
    "\n",
    "In this section, we will configure two key components of our project:\n",
    "\n",
    "1. **MediaPipe**: A powerful library for real-time perception tasks such as hand tracking, face detection, and pose estimation. It processes video frames to extract meaningful landmarks (e.g., hand positions) which we can use creatively.\n",
    "   \n",
    "2. **OSC (Open Sound Control)**: A protocol used to send data between different software or hardware. We'll use the Python-OSC library to transmit the data extracted by MediaPipe to other applications, such as Processing or Max/MSP.\n",
    "\n",
    "The code below initializes these components and prepares them to work together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733322534.170595 2068410 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1733322534.263793 2068726 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733322534.275975 2068726 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# Setup OSC\n",
    "OSC_IP = \"127.0.0.1\"  # Local address\n",
    "OSC_PORT = 12000       # Port for Processing\n",
    "client = SimpleUDPClient(OSC_IP, OSC_PORT)\n",
    "\n",
    "# Setup MediaPipe\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing Available Camera Devices\n",
    "\n",
    "Before starting the video capture, it's important to know which camera devices are available in the system. This step scans for connected cameras and lists their indices (used to access them in OpenCV) along with their names (if supported). \n",
    "\n",
    "Use this information to select the correct camera for the application. If no cameras are detected, ensure your device is connected properly or check for driver issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for available camera devices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 15:29:45.784 python[15099:2068410] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: Unknown\n",
      "Index 1: Unknown\n",
      "Index 2: Unknown\n",
      "Index 3: Unknown\n",
      "[12/04 15:29:48.710155][info][2068410][Context.cpp:69] Context created with config: default config!\n",
      "[12/04 15:29:48.710297][info][2068410][Context.cpp:74] Context work_dir=/Users/linalopes/Desktop/tracking-body\n",
      "[12/04 15:29:48.710298][info][2068410][Context.cpp:77] \t- SDK version: 1.9.4\n",
      "[12/04 15:29:48.710299][info][2068410][Context.cpp:78] \t- SDK stage version: main\n",
      "[12/04 15:29:48.710301][info][2068410][Context.cpp:82] get config EnumerateNetDevice:false\n",
      "[12/04 15:29:48.710535][info][2068410][MacPal.cpp:36] createObPal: create MacPal!\n",
      "[12/04 15:29:48.718112][info][2068410][MacPal.cpp:104] Create PollingDeviceWatcher!\n",
      "[12/04 15:29:48.718125][info][2068410][DeviceManager.cpp:15] Current found device(s): (0)\n",
      "[12/04 15:29:48.718274][info][2068410][Pipeline.cpp:15] Try to create pipeline with default device.\n",
      "[12/04 15:29:48.718279][warning][2068410][ObException.cpp:5] No device found, fail to create pipeline!\n",
      "[12/04 15:29:48.726931][info][2068410][Context.cpp:90] Context destroyed\n",
      "Index 4: No device detected.\n",
      "[12/04 15:29:48.740219][info][2068410][Context.cpp:69] Context created with config: default config!\n",
      "[12/04 15:29:48.740235][info][2068410][Context.cpp:74] Context work_dir=/Users/linalopes/Desktop/tracking-body\n",
      "[12/04 15:29:48.740236][info][2068410][Context.cpp:77] \t- SDK version: 1.9.4\n",
      "[12/04 15:29:48.740237][info][2068410][Context.cpp:78] \t- SDK stage version: main\n",
      "[12/04 15:29:48.740240][info][2068410][Context.cpp:82] get config EnumerateNetDevice:false\n",
      "[12/04 15:29:48.740244][info][2068410][MacPal.cpp:36] createObPal: create MacPal!\n",
      "[12/04 15:29:48.745462][info][2068410][MacPal.cpp:104] Create PollingDeviceWatcher!\n",
      "[12/04 15:29:48.745470][info][2068410][DeviceManager.cpp:15] Current found device(s): (0)\n",
      "[12/04 15:29:48.745474][info][2068410][Pipeline.cpp:15] Try to create pipeline with default device.\n",
      "[12/04 15:29:48.745477][warning][2068410][ObException.cpp:5] No device found, fail to create pipeline!\n",
      "[12/04 15:29:48.745674][info][2068410][Context.cpp:90] Context destroyed\n",
      "Index 5: No device detected.\n",
      "[12/04 15:29:48.758309][info][2068410][Context.cpp:69] Context created with config: default config!\n",
      "[12/04 15:29:48.758325][info][2068410][Context.cpp:74] Context work_dir=/Users/linalopes/Desktop/tracking-body\n",
      "[12/04 15:29:48.758327][info][2068410][Context.cpp:77] \t- SDK version: 1.9.4\n",
      "[12/04 15:29:48.758328][info][2068410][Context.cpp:78] \t- SDK stage version: main\n",
      "[12/04 15:29:48.758330][info][2068410][Context.cpp:82] get config EnumerateNetDevice:false\n",
      "[12/04 15:29:48.758331][info][2068410][MacPal.cpp:36] createObPal: create MacPal!\n",
      "[12/04 15:29:48.758745][info][2068410][MacPal.cpp:104] Create PollingDeviceWatcher!\n",
      "[12/04 15:29:48.758751][info][2068410][DeviceManager.cpp:15] Current found device(s): (0)\n",
      "[12/04 15:29:48.758753][info][2068410][Pipeline.cpp:15] Try to create pipeline with default device.\n",
      "[12/04 15:29:48.758755][warning][2068410][ObException.cpp:5] No device found, fail to create pipeline!\n",
      "[12/04 15:29:48.759060][info][2068410][Context.cpp:90] Context destroyed\n",
      "Index 6: No device detected.\n",
      "[12/04 15:29:48.771128][info][2068410][Context.cpp:69] Context created with config: default config!\n",
      "[12/04 15:29:48.771145][info][2068410][Context.cpp:74] Context work_dir=/Users/linalopes/Desktop/tracking-body\n",
      "[12/04 15:29:48.771146][info][2068410][Context.cpp:77] \t- SDK version: 1.9.4\n",
      "[12/04 15:29:48.771147][info][2068410][Context.cpp:78] \t- SDK stage version: main\n",
      "[12/04 15:29:48.771150][info][2068410][Context.cpp:82] get config EnumerateNetDevice:false\n",
      "[12/04 15:29:48.771151][info][2068410][MacPal.cpp:36] createObPal: create MacPal!\n",
      "[12/04 15:29:48.771784][info][2068410][MacPal.cpp:104] Create PollingDeviceWatcher!\n",
      "[12/04 15:29:48.771790][info][2068410][DeviceManager.cpp:15] Current found device(s): (0)\n",
      "[12/04 15:29:48.771792][info][2068410][Pipeline.cpp:15] Try to create pipeline with default device.\n",
      "[12/04 15:29:48.771793][warning][2068410][ObException.cpp:5] No device found, fail to create pipeline!\n",
      "Index 7: No device detected.\n",
      "[12/04 15:29:48.772024][info][2068410][Context.cpp:90] Context destroyed\n",
      "[12/04 15:29:48.784047][info][2068410][Context.cpp:69] Context created with config: default config!\n",
      "[12/04 15:29:48.784070][info][2068410][Context.cpp:74] Context work_dir=/Users/linalopes/Desktop/tracking-body\n",
      "[12/04 15:29:48.784071][info][2068410][Context.cpp:77] \t- SDK version: 1.9.4\n",
      "[12/04 15:29:48.784072][info][2068410][Context.cpp:78] \t- SDK stage version: main\n",
      "[12/04 15:29:48.784075][info][2068410][Context.cpp:82] get config EnumerateNetDevice:false\n",
      "[12/04 15:29:48.784076][info][2068410][MacPal.cpp:36] createObPal: create MacPal!\n",
      "[12/04 15:29:48.785390][info][2068410][MacPal.cpp:104] Create PollingDeviceWatcher!\n",
      "[12/04 15:29:48.785395][info][2068410][DeviceManager.cpp:15] Current found device(s): (0)\n",
      "[12/04 15:29:48.785397][info][2068410][Pipeline.cpp:15] Try to create pipeline with default device.\n",
      "[12/04 15:29:48.785399][warning][2068410][ObException.cpp:5] No device found, fail to create pipeline!\n",
      "Index 8: No device detected.\n",
      "[12/04 15:29:48.785633][info][2068410][Context.cpp:90] Context destroyed\n",
      "[12/04 15:29:48.797269][info][2068410][Context.cpp:69] Context created with config: default config!\n",
      "[12/04 15:29:48.797286][info][2068410][Context.cpp:74] Context work_dir=/Users/linalopes/Desktop/tracking-body\n",
      "[12/04 15:29:48.797287][info][2068410][Context.cpp:77] \t- SDK version: 1.9.4\n",
      "[12/04 15:29:48.797288][info][2068410][Context.cpp:78] \t- SDK stage version: main\n",
      "[12/04 15:29:48.797290][info][2068410][Context.cpp:82] get config EnumerateNetDevice:false\n",
      "[12/04 15:29:48.797292][info][2068410][MacPal.cpp:36] createObPal: create MacPal!\n",
      "[12/04 15:29:48.797651][info][2068410][MacPal.cpp:104] Create PollingDeviceWatcher!\n",
      "[12/04 15:29:48.797656][info][2068410][DeviceManager.cpp:15] Current found device(s): (0)\n",
      "[12/04 15:29:48.797658][info][2068410][Pipeline.cpp:15] Try to create pipeline with default device.\n",
      "[12/04 15:29:48.797660][warning][2068410][ObException.cpp:5] No device found, fail to create pipeline!\n",
      "Index 9: No device detected.\n",
      "[12/04 15:29:48.797849][info][2068410][Context.cpp:90] Context destroyed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: out device of bound (0-3): 4\n",
      "OpenCV: camera failed to properly initialize!\n",
      "[ WARN:0@62.939] global cap.cpp:323 open VIDEOIO(OBSENSOR): raised unknown C++ exception!\n",
      "\n",
      "\n",
      "OpenCV: out device of bound (0-3): 5\n",
      "OpenCV: camera failed to properly initialize!\n",
      "[ WARN:0@62.957] global cap.cpp:323 open VIDEOIO(OBSENSOR): raised unknown C++ exception!\n",
      "\n",
      "\n",
      "OpenCV: out device of bound (0-3): 6\n",
      "OpenCV: camera failed to properly initialize!\n",
      "[ WARN:0@62.970] global cap.cpp:323 open VIDEOIO(OBSENSOR): raised unknown C++ exception!\n",
      "\n",
      "\n",
      "OpenCV: out device of bound (0-3): 7\n",
      "OpenCV: camera failed to properly initialize!\n",
      "[ WARN:0@62.983] global cap.cpp:323 open VIDEOIO(OBSENSOR): raised unknown C++ exception!\n",
      "\n",
      "\n",
      "OpenCV: out device of bound (0-3): 8\n",
      "OpenCV: camera failed to properly initialize!\n",
      "[ WARN:0@62.997] global cap.cpp:323 open VIDEOIO(OBSENSOR): raised unknown C++ exception!\n",
      "\n",
      "\n",
      "OpenCV: out device of bound (0-3): 9\n",
      "OpenCV: camera failed to properly initialize!\n",
      "[ WARN:0@63.009] global cap.cpp:323 open VIDEOIO(OBSENSOR): raised unknown C++ exception!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def list_camera_devices():\n",
    "    \"\"\"Lists available camera devices with their names (if supported).\"\"\"\n",
    "    print(\"Scanning for available camera devices...\")\n",
    "    available_cameras = []\n",
    "    for index in range(10):  # Check up to 10 camera indices\n",
    "        cap = cv2.VideoCapture(index)\n",
    "        if cap.isOpened():\n",
    "            # Try to fetch the camera's name, if available\n",
    "            camera_name = cap.get(cv2.CAP_PROP_DEVICE_NAME) if hasattr(cv2, 'CAP_PROP_DEVICE_NAME') else \"Unknown\"\n",
    "            print(f\"Index {index}: {camera_name}\")\n",
    "            available_cameras.append((index, camera_name))\n",
    "            cap.release()\n",
    "        else:\n",
    "            print(f\"Index {index}: No device detected.\")\n",
    "    if not available_cameras:\n",
    "        print(\"No camera devices found.\")\n",
    "    return available_cameras\n",
    "\n",
    "# Call the function to list devices before starting video capture\n",
    "cameras = list_camera_devices()\n",
    "if not cameras:\n",
    "    print(\"No cameras available. Exiting.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Capture and Processing Loop\n",
    "\n",
    "This part of the code is the heart of the program, where video frames are captured, processed, and visualized in real-time. Here's a breakdown of what each section does:\n",
    "\n",
    "1. **Video Capture Initialization**:\n",
    "   - `cv2.VideoCapture(2)`: Opens a connection to the webcam (or a specific video source). Replace `2` with `0` or `1` if the camera index needs adjustment for your system.\n",
    "\n",
    "2. **Frame Reading**:\n",
    "   - `ret, frame = cap.read()`: Reads each frame from the webcam. If `ret` is `False`, it means there are no more frames (e.g., the camera was disconnected).\n",
    "\n",
    "3. **Image Conversion**:\n",
    "   - `cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)`: Converts the frame from BGR to RGB, as MediaPipe expects RGB images for processing.\n",
    "\n",
    "4. **MediaPipe Pose Processing**:\n",
    "   - `pose.process(rgb_frame)`: Processes the frame to detect pose landmarks. These landmarks represent keypoints (e.g., joints) of a human pose.\n",
    "\n",
    "5. **Visualization (Optional)**:\n",
    "   - `mp_drawing.draw_landmarks`: Draws the detected pose landmarks and their connections on the video frame for visualization.\n",
    "\n",
    "6. **Send Data via OSC**:\n",
    "   - The keypoints from `results.pose_landmarks` are normalized (values between 0 and 1) and prepared as a list. These are sent via OSC to external applications, such as Processing, using the `/pose` OSC address.\n",
    "\n",
    "7. **Video Display (Optional)**:\n",
    "   - `cv2.imshow('MediaPipe Pose', frame)`: Displays the video frame with landmarks overlaid. This helps verify the system's operation.\n",
    "\n",
    "8. **Quit the Loop**:\n",
    "   - `cv2.waitKey(1) & 0xFF == ord('q')`: Checks if the \"q\" key is pressed. If so, it breaks the loop and ends the program.\n",
    "\n",
    "9. **Release Resources**:\n",
    "   - `cap.release()`: Releases the webcam resource.\n",
    "   - `cv2.destroyAllWindows()`: Closes any OpenCV-created windows.\n",
    "\n",
    "This loop ensures continuous video capture and processing, making it possible to track pose landmarks in real-time and transmit their data seamlessly to other tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3q/cnhcx09j2sl7jctskk94y5280000gn/T/ipykernel_15099/272797317.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Video capture\n",
    "cap = cv2.VideoCapture(3) # Put here the index of the camera device\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert image to RGB (MediaPipe uses RGB)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    # Draw points on the frame (optional, for visualization)\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "        # Send keypoints via OSC\n",
    "        keypoints = []\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            keypoints.extend([landmark.x, landmark.y])  # Normalized (0-1)\n",
    "        client.send_message(\"/pose\", keypoints)\n",
    "\n",
    "    # Show video with points (optional)\n",
    "    cv2.imshow('MediaPipe Pose', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
